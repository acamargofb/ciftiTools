fname <- 'clever_results'
if(is.null(opts$csv)){ opts$csv <- fname }
if(!endsWith('.csv', opts$csv)){ opts$csv <- paste0(opts$csv, '.csv') }
if(file.exists(opts$csv)){ opts$csv <- generate_fname(opts$csv) }
if(is.null(opts$png)){ opts$png <- fname }
if(!endsWith('.png', opts$png)){ opts$png <- paste0(opts$png, '.png') }
if(file.exists(opts$png)){ opts$png <- generate_fname(opts$png) }
if(params.clever$id_out){
## Save to png.
plt <- do.call(plot, append(list(clev), params.plot[is.null(params.plot)]))
if(dirname(opts$png) != '.'){
if(!dir.exists(dirname(opts$png))){dir.create(dirname(opts$png))}
}
ggsave(filename = opts$png, plot=plt)
## Save to csv.
table <- clever_to_table(clev)
if(dirname(opts$csv) != '.'){
if(!dir.exists(dirname(opts$csv))){dir.create(dirname(opts$csv))}
}
write.csv(table, file=opts$csv, row.names=FALSE)
}
plot(clev)
gc()
# Load required packages, installing if needed.
#pkg <- c('oro.nifti', 'rjson', 'clever', 'ggplot2')
#pkg.new <- pkg[!(pkg %in% installed.packages()[,'Package'])] #or from github?
#if(length(pkg.new)){ install.packages(pkg.new) }
#lapply(pkg, require, character.only = TRUE)
#rm(pkg, pkg.new)
library(RNifti)
library(rjson)
library(clever)
library(ggplot2)
source('utils.R')
#' Centers and scales a matrix robustly for the purpose of covariance estimation.
#'
#' Centers each column on its median, and scales each column by its median
#' absolute deviation (MAD). If any column MAD is zero, its values become zero
#' and a warning is raised. If all MADs are zero, an error is raised.
#'
#' @param mat A numerical matrix.
#'
#' @return The input matrix centered and scaled.
#'
#' @importFrom miscTools colMedians
scale_med <- function(mat){
# mat is nxp; we want to scale the columns.
n <- nrow(mat)
p <- ncol(mat)
# Center.
mat <- sweep(mat, 2, colMedians(mat, na.rm=TRUE), '-')
# Compute MAD and check for zero-variance voxels.
mad <- 1.4826 * colMedians(abs(mat), na.rm=TRUE)
zero_mad <- mad == 0
if(any(zero_mad)){
if(all(zero_mad)){
stop("All voxels are zero-variance.\n")
} else {
warning(cat("Warning: ", sum(zero_mad),
" zero-variance voxels (out of ", length(zero_mad),
"). These will be set to zero for estimation of the covariance.\n", sep=""))
}
}
# Scale.
scale_col <- function(col, v){ return(ifelse(v != 0, col/v, 0)) }
mat_scaled <- sweep(mat, 2, mad, scale_col)
return(mat_scaled)
}
#' Computes the log likelihood of a sample of values from an F distribution.
#'
#' @param par A vector of length two which contains the degrees of freedom values.
#' @param vals A vector of values for which log likelihood will be calculated.
#' @param cutoff Values greater than the cutoff are removed before log likelihood calculation.
#'
#' @return A scalar which represents the log likelihood.
logL.F <- function(par, vals, cutoff){
df1 <- par[1]
df2 <- par[2]
vals <- vals[vals <= cutoff]
return(-1*sum(log(df(vals, df1, df2)) - log(pf(cutoff, df1, df2))))
}
#' Computes the log likelihood of a sample of values from a log normal distribution.
#'
#' @param par A vector of length two which contains the degrees of freedom values.
#' @param vals A vector of values for which log likelihood will be calculated.
#' @param cutoff Values greater than the cutoff are removed before log likelihood calculation.
#'
#' @return A scalar which represents the log likelihood.
logL.lnorm <- function(par, vals, cutoff){
mean <- par[1]
sd <- par[2]
vals <- vals[vals <= cutoff]
return(-1*sum(log(dlnorm(vals, mean, sd)) - log(plnorm(cutoff, mean, sd))))
}
#' Estimates the trend of \code{ts} using a robust discrete cosine transform.
#'
#' @param ts A numeric vector to detrend.
#' @param robust Should a robust linear model be used? Default FALSE.
#'
#' @return The estimated trend.
#'
#' @importFrom robustbase lmrob
#' @importFrom robustbase lmrob.control
#' @export
est_trend <- function(ts, robust=TRUE){
df <- data.frame(
index=1:length(ts),
ts=ts
)
i_scaled <- 2*(df$index-1)/(length(df$index)-1) - 1 #range on [-1, 1]
df['p1'] <- cos(2*pi*(i_scaled/4 - .25)) #cosine on [-1/2, 0]*2*pi
df['p2'] <- cos(2*pi*(i_scaled/2 - .5)) #cosine on [-1, 0]*2*pi
df['p3'] <- cos(2*pi*(i_scaled*3/4  -.75)) # [-1.5, 0]*2*pi
df['p4'] <- cos(2*pi*(i_scaled - 1)) # [2, 0]*2*pi
if(robust){
control <- lmrob.control(scale.tol=1e-3, refine.tol=1e-2) # increased tol.
# later: warn.limit.reject=NULL
trend <- lmrob(ts~p1+p2+p3+p4, df, control=control)$fitted.values
} else {
trend <- lm(ts~p1+p2+p3+p4, df)$fitted.values
}
return(trend)
}
# Read input from JSON.
input <- fromJSON(file = 'config.json')
input[input == ''] = NULL
if(!is.null(input$id_out)){ input$id_out <- as.logical(input$id_out) }
if(is.na(input$id_out)){ stop('Invalid "id_out" argument.') }
input$kurt_quantile_cut <- as.numeric(input$kurt_quantile_cut)
input$kurt_detrend <- as.logical(input$kurt_detrend)
input$id_out <- as.logical(input$id_out)
params.clever <- input[names(input) %in% c('choosePCs', 'kurt_quantile_cut', 'kurt_detrend',
'method', 'id_out')]
params.plot <- input[names(input) %in% c('main','sub','xlab','ylab')]
opts <- input[names(input) %in% c('out_dir','csv','png')]
opts <- opts[is.null(opts)]
params.clever
params.clever = params.clever[3:4]
input$bold = 'bold.nii.gz'
input$mask = 'mask.nii.gz'
print('Garbage collection before doing anything:')
print(gc(verbose=TRUE))
# Vectorize data.
print('(1) Vectorizing...')
Dat <- vectorize_NIftI(input$bold, input$mask)
# Represents NIfTI volume timeseries as matrix.
vectorize_NIftI = function(bold_fname, mask_fname, chunk_size=0){
print('Reading mask.')
mask <- RNifti::readNifti(mask_fname, internal=FALSE)
print('Mask dims are:')
print(dim(mask))
mask <- mask > 0
nV <- sum(mask)
print(paste0('Mask density is ', round(nV/prod(dim(mask)), 2), '.'))
if(is.null(chunk_size) | (chunk_size < 1)){
print('Reading bold.')
dat <- RNifti::readNifti(bold_fname, internal=TRUE)
print(paste0('Bold dims are:'))
print(dim(dat))
if(dim(dat)[1:3] != dim(mask)[1:3]){
stop('Error: bold and mask dims do not match.')
}
nT <- dim(dat)[4]
gc()
print(paste0('Initializing a matrix of size ', nT, ' by ', nV, '.'))
Dat <- matrix(NA, nT, nV)
print('Beginning mask loop.')
for(t in 1:nT){
dat_t <- dat[,,,t]
Dat[t,] <- dat_t[mask]
}
print('Ended mask loop.')
} else {
stop('Chunkwise vectorizing does not work right now.')
print('Reading bold in chunks.')
bold_dims <- niftiHeader(bold_fname)$dim
print(paste0('According to its header, bold dims are:'))
print(bold_dims[2:5])
nT <- bold_dims[5]
print(paste0('Initializing a matrix of size ', nT, ' by ', nV, '.'))
Dat <- matrix(NA, nT, nV)
print('Beginning mask loop.')
chunks <- split(1:nT, ceiling(seq_along(1:nT)/chunk_size))
good_brick = 1
for(i in 1:length(chunks)){
ts = chunks[[i]]
print(paste0('Chunk ', i, ':t ', ts[1], ' to ', ts[length(ts)]))
dat <- tryCatch(
expr = {
x <- RNifti::readNifti(bold_fname, volumes=ts)
good_brick = ts[1]
x
},
error = {
function(e){
print(paste0('Warning: This chunk could not be read from t ', ts[1]))
print(paste0('So, reading from ', good_brick, ' and taking subset.'))
x <- RNifti::readNifti(bold_fname,
volumes=good_brick:(ts[length(ts)]))
return ( x[,,,ts-good_brick+1] )
}
}
)
for(i in 1:length(ts)){
t <- ts[i]
dat_t <- dat[,,,i]
Dat[t,] <- dat_t[mask]
rm(dat_t)
}
rm(dat)
}
print('Ended mask loop.')
}
return(Dat)
}
# Creates a new file name from an existing one. Used to avoid duplicate names.
generate_fname = function(existing_fname){
last_period_index <- regexpr("\\.[^\\.]*$", existing_fname)
if(last_period_index == -1){ warning('Not a file name (no extension).') }
extension <- substr(existing_fname, last_period_index, nchar(existing_fname))
## If parenthesized number suffix exists...
if(substr(existing_fname, last_period_index-1, last_period_index-1) == ')'){
in_last_parenthesis <- gsub(paste0('(*\\))', extension), '',
gsub('.*(*\\()', '', existing_fname))
n <- suppressWarnings(as.numeric(in_last_parenthesis))
if(is.numeric(n)){
if(!is.na(n)){
## ...add one.
np1 <- as.character(n + 1)
n <- as.character(n)
out <- gsub(
paste0( '(\\(', n, '\\))', extension),
paste0('\\(', np1, '\\)', extension),
existing_fname)
}
}
}
## Otherwise, append "(1)".
out <- gsub(extension, paste0('(1)', extension), existing_fname)
## Try again if it still exists.
if(file.exists(out)){ return(generate_fname(out)) }
return(out)
}
# Represents a clever object as a JSON file.
clever_to_json = function(clev, params.plot=NULL, opts.png=NULL){
choosePCs <- clev$params$choosePCs
method <- clev$params$method
measure <- switch(method,
leverage=clev$leverage,
robdist=clev$robdist,
robdist_subset=clev$robdist)
outliers <- clev$outliers
cutoffs <- clev$cutoffs
root <- frame()
root$brainlife <- list()
if(!is.null(opts.png)){
msg <- frame()
msg$type <- "success"
msg$msg <- "See clever_results.png for the outlier detection plot."
}
root$brainlife$msg <- msg
#img <- frame()
#img$type <- "image/png"
#img$name <- "clever result"
#img$base64 <- toJSON(plt) # does not work.
graph1 <- frame()
graph1$layout <- frame()
graph1$layout$xaxis <- frame()
graph1$layout$yaxis <- frame()
graph1$type <- "plotly"
if(is.null(params.plot)){
params.plot=list(main=NULL, xlab=NULL, ylab=NULL)
}
graph1$name <- ifelse(!is.null(params.plot$main),
params.plot$main,
paste0('Outlier Distribution',
ifelse(sum(apply(outliers, 2, sum)) > 0, '', ' (None Identified)')))
graph1$layout$xaxis$title <- ifelse(!is.null(params.plot$xlab),
params.plot$xlab,
'Index (Time Point)')
graph1$layout$xaxis$type <- "linear"
graph1$layout$yaxis$title <- ifelse(!is.null(params.plot$ylab),
params.plot$ylab,
method)
graph1$layout$yaxis$type <- "linear"
graph1$data <- list(list(y=round(measure, digits=5)))
root$brainlife$graph1 <- graph1
return(root)
}
# Represents a clever object as a data.frame.
clever_to_table = function(clev){
choosePCs <- clev$params$choosePCs
method <- clev$params$method
measure <- switch(method,
leverage=clev$leverage,
robdist=clev$robdist,
robdist_subset=clev$robdist)
outliers <- clev$outliers
cutoffs <- clev$cutoffs
table <- data.frame(measure)
if(!is.null(outliers)){
table <- cbind(table, outliers)
}
names(table) <- c(
paste0(method, '. PCs chosen by ', choosePCs),
paste0(names(outliers), ' = ', cutoffs))
if(!is.null(clev$in_MCD)){
table <- cbind(table, in_MCD=clev$in_MCD)
}
return(table)
}
print('Garbage collection before doing anything:')
print(gc(verbose=TRUE))
# Vectorize data.
print('(1) Vectorizing...')
Dat <- vectorize_NIftI(input$bold, input$mask)
if(any(is.na(Dat))){ stop('Error: NA in vectorized volume.') }
print('Garbage collection after vectorizing bold:')
print(gc(verbose=TRUE))
print('Size of vectorized matrix:')
print(object.size(Dat), units='Mb')
# Perform clever.
print('(2) Performing clever...')
clev <- do.call(clever::clever, append(list(Dat), params.clever))
# Save results...
print('(3) Saving results...')
## Use default options if unspecified.
cwd <- getwd()
if(is.null(opts$out_dir)){ opts$out_dir <- cwd }
if(!dir.exists(opts$out_dir)){dir.create(opts$out_dir)}
setwd(opts$out_dir)
fname <- 'clever_results'
if(is.null(opts$csv)){ opts$csv <- fname }
if(!endsWith('.csv', opts$csv)){ opts$csv <- paste0(opts$csv, '.csv') }
if(file.exists(opts$csv)){ opts$csv <- generate_fname(opts$csv) }
if(is.null(opts$png)){ opts$png <- fname }
if(!endsWith('.png', opts$png)){ opts$png <- paste0(opts$png, '.png') }
if(file.exists(opts$png)){ opts$png <- generate_fname(opts$png) }
if(params.clever$id_out){
## Save to png.
plt <- do.call(plot, append(list(clev), params.plot[is.null(params.plot)]))
if(dirname(opts$png) != '.'){
if(!dir.exists(dirname(opts$png))){dir.create(dirname(opts$png))}
}
ggsave(filename = opts$png, plot=plt)
## Save to csv.
table <- clever_to_table(clev)
if(dirname(opts$csv) != '.'){
if(!dir.exists(dirname(opts$csv))){dir.create(dirname(opts$csv))}
}
write.csv(table, file=opts$csv, row.names=FALSE)
}
## Write the JSON file.
root <- clever_to_json(clev, params.plot, opts$png)
write(toJSON(root), "product.json")
setwd(cwd)
library(robustbase)
Dat = Dat - rowMedians(Dat, na.rm=TRUE)
rowMedians(Dat, na.rm=TRUE)
Dat <- t(Dat)[,100:1000]
dim(Dat)
D2 <- Dat[,100:300]
D2 - rowMedians(D2, na.rm=TRUE)
rowMedians(D2)
dim(D2)
D2 = D2 - c(1,2)
D2 = D2 - c(1,2,3,4,5,6,7)
dim(rowMedians(D2))
length(rowMedians(D2))
length(rowMedians(D2, na.rm=TRUE))
dim(rowMedians(D2, na.rm=TRUE))
rowMedians(D2) == 0
rowMedians(D2, na.rm=TRUE) == 0
identical(rowMedians(D2, na.rm=TRUE), c(rowMedians(D2, na.rm=TRUE)))
D2 = t(D2)
dim(D2)
D2 = t(D2)
D2 = crossprod(D2)
dim(D2)
x = c(0,0,1,1,1,2)
x[x==0]=1
x
dim(D2)
x = rep(F, 201)
x[2,4,6,4,5,4,35,35,15] = T
x[c(2,4,6,42,5,43,5,35,15)] = T
D2[x,] = F
1e-8
1e-8*10^8
files.sources <- list.files("ciftiTools/R")
sapply(paste0("ciftiTools/R/", files.sources), source)
library(devtools)
library(gifti)
library(oro.nifti)
files.sources <- list.files("ciftiTools/R")
sapply(paste0("ciftiTools/R/", files.sources), source)
library(devtools)
library(gifti)
library(oro.nifti)
Dat_prefix <- "ciftiTools_Data/645450.32k.rfMRI_REST1_LR_Atlas_MSMAll_hp2000_clean"
wb_dir <- "workbench/bin_linux64/wb_command.exe"
fname_gifti_left = "ciftiTools_Data/645450.32k.rfMRI_REST1_LR_Atlas_MSMAll_hp2000_clean.L.func.gii"
fname_gifti_right = "ciftiTools_Data/645450.32k.rfMRI_REST1_LR_Atlas_MSMAll_hp2000_clean.R.func.gii"
surf_names='surface'
brainstructures=c('left','right','subcortical')
Dat_fname <- "Desktop/ciftiTools_Data/rfMRI_REST1_LR_Atlas_MSMAll.dtseries.nii"
gL_fname = "Desktop/ciftiTools_Data/Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii"
gR_fname = "Desktop/ciftiTools_Data/Q1-Q6_R440.R.inflated.32k_fs_LR.surf.gii"
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname)
Dat_fname <- "ciftiTools_Data/rfMRI_REST1_LR_Atlas_MSMAll.dtseries.nii"
gL_fname = "ciftiTools_Data/Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii"
gR_fname = "ciftiTools_Data/Q1-Q6_R440.R.inflated.32k_fs_LR.surf.gii"
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname)
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname, wb_cmd="workbench/bin_linux64/wb_cmd.exe")
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname, wb_cmd="workbench/bin_linux64/wb_command.exe")
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname, wb_cmd="workbench/exe_linux64/wb_command")
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname, wb_cmd="workbench/exe_linux64/wb_command.exe")
Dat <- cifti_read_separate(Dat_fname, gL_fname, gR_fname, wb_cmd="workbench/bin_linux64/wb_command")
cifti_view(Dat)
cifti_view(Dat, brainstructure=c("left"))
install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(INLA)
cifti_view(Dat, brainstructure=c("left"))
cifti_view(Dat, brainstructure=c("subcortical"))
View(cifti_read_separate)
View(cifti_view)
cifti_view(Dat, brainstructure=c("surface"))
files.sources <- list.files("ciftiTools/R")
sapply(paste0("ciftiTools/R/", files.sources), source)
library(devtools)
library(gifti)
library(oro.nifti)
library(e1071)
library(robustbase)
Dat3_fname <- "Data/sample_data_Damon/rfMRI_REST1_LR_Atlas_MSMAll_hp2000_clean.dtseries.nii"
Dat <- cifti_read_separate(Dat3_fname, wb_cmd="workbench/bin_linux64/wb_command")
Dat <- t(matrix(Dat$VOL@.Data, ncol=Dat$VOL@dim_[5]))
files.sources <- list.files("clever/R")
files.sources <- files.sources[files.sources != "sysdata.rda"]
sapply(paste0("clever/R/", files.sources), source)
x=apply(Dat, 2, mad)
hist(x)
hist(x, bins=200)
hist(x, breaks=100)
hist(Dat[1,])
summary(Dat[1,])
summary(x)
dim(Dat)
summary(Dat[,])
1
summary(Dat[,1])
View(cifti_read_separate)
x=readNIfTI("Desktop/Data/rfMRI_REST1_LR_Atlas_MSMAll.nii.gz")
apply(t(matrix(x, ncol=1200)), 2, mad)
library(knitr)
opts_chunk$set(autodep = TRUE, cache = TRUE)
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot())
library(devtools)
devtools::install_github('mandymejia/clever', ref='2.0')
library(clever)
data(Dat1)
data(Dat2)
dim(Dat1)
dim(Dat2)
?clever
clever.Dat1.var.lev = clever(Dat1, verbose=TRUE, DVARS=FALSE, lev_images=FALSE)
clever.Dat2.var.lev = clever(Dat2, verbose=TRUE, DVARS=FALSE, lev_images=FALSE)
plot_grid(plot(clever.Dat1.var.lev, plot_title="Dat1"), plot(clever.Dat2.var.lev, plot_title="Dat2"), nrow=1)
clever.Dat1 = clever(Dat1, projection_methods="all", outlyingness_methods="all", verbose=TRUE)
clever.Dat2 = clever(Dat2, projection_methods="all", outlyingness_methods="all", verbose=TRUE)
plot(clever.Dat1, "all", plot_title="Dat1")
plot(clever.Dat2, "all", plot_title="Dat2")
library(oro.nifti)
library(neurobase)
#'  Selects a timepoint from a volume time series, and returns it after adding
#'  the NIfTI header from the mask onto it.
#' @param VolumeTimeSeries A 4D matrix. Time is on the 4th dimension.
#' @param time The timepoint to select.
#' @param mask The corresponding mask.
#'
#' @return The 3D volume with the NIfTI header from the mask.
Volume_to_NIfTI <- function(VolumeTimeSeries, time, mask){
vol <- VolumeTimeSeries[,,,time]
vol <- copyNIfTIHeader(img=mask, arr=vol)
return(vol)
}
fname = system.file("extdata", "Dat1_mask.nii.gz", package = "clever")
Mask1 = readNIfTI(fname) #Pitt_0050048 (full of artifacts)
Img1 = Matrix_to_VolumeTimeSeries(Dat1, Mask1)
fname = system.file("extdata", "Dat2_mask.nii.gz", package = "clever")
Mask2 = readNIfTI(fname)
Img2 = Matrix_to_VolumeTimeSeries(Dat2, Mask2)
par(mfrow=c(1,2))
levs = clever.Dat1$outlier_measures$PCA_var__leverage
t_med = order(levs)[ceiling(length(levs)/2)]
t_max = which.max(levs)
image(Img1[,,,t_med], main=paste0('Median leverage (T = ', t_med, ')'))
image(Img1[,,,t_max], main=paste0('Maximum leverage (T = ', t_max, ')'))
Lev_Img1 = clever.Dat1$outlier_lev_imgs$PCA_var__leverage
print('The timepoints meeting the first outlier level threshold:')
paste(row.names(Lev_Img1$mean), collapse=", ")
par(mfrow=c(1,2))
# Constant voxels are deleted during the clever algorithm, so the leverage images will have
# missing values where the constant voxels were. The NA_fill option is used here to make
# these voxels have the same color as the background (out-of-mask voxels).
Lev_Img1.mean = Matrix_to_VolumeTimeSeries(Lev_Img1$mean, Mask1, NA_fill=0)
Lev_Img1.top = Matrix_to_VolumeTimeSeries(Lev_Img1$top, Mask1, NA_fill=0)
image(Lev_Img1.mean[,,,1], main=paste0('Lev. img., mean dir. (T=59)'))
image(Lev_Img1.top[,,,1], main=paste0('Lev. img., top dir. (T=59)'))
setwd("Desktop/ciftiTools")
